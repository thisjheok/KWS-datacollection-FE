import {
  BORDERLINE_QUIET_RMS_THRESHOLD,
  CLIP_LEVEL,
  CLIP_RATIO_THRESHOLD,
  EARLY_END_MS,
  FLATLINE_ABS_MAX_THRESHOLD,
  FLATLINE_RMS_THRESHOLD,
  FRAME_SIZE,
  GATE_TARGET_SAMPLE_COUNT,
  GATE_TARGET_SAMPLE_RATE,
  LATE_START_MS,
  MIN_SPEECH_SPAN_MS,
  NO_SPEECH_RATIO_THRESHOLD,
  PASS_SPEECH_RATIO_THRESHOLD,
  SPEECH_FRAME_RMS_THRESHOLD,
  TOO_QUIET_RMS_THRESHOLD,
} from './gateConfig'

export type GateDecision = 'PASS' | 'AMBIG' | 'REJECT'
export type GateReason =
  | 'TooQuiet'
  | 'NoSpeech'
  | 'Flatline'
  | 'BorderlineQuiet'
  | 'ClippingSuspected'
  | 'SpeechOffCenter'
  | 'Ok'

export type GateResult = {
  decision: GateDecision
  reason: GateReason
  userMessage: string
  debugMetrics: {
    rms: number
    absMax: number
    clipRatio: number
    speechRatio: number
    firstSpeechMs: number | null
    lastSpeechMs: number | null
  }
}

const normalizePcmLength = (pcm: Float32Array): Float32Array => {
  if (pcm.length === GATE_TARGET_SAMPLE_COUNT) {
    return pcm
  }

  const normalized = new Float32Array(GATE_TARGET_SAMPLE_COUNT)
  normalized.set(pcm.subarray(0, GATE_TARGET_SAMPLE_COUNT))
  return normalized
}

const buildResult = (
  decision: GateDecision,
  reason: GateReason,
  userMessage: string,
  debugMetrics: GateResult['debugMetrics'],
): GateResult => ({
  decision,
  reason,
  userMessage,
  debugMetrics,
})

export const analyzePcmForSpeechGate = (pcm: Float32Array, sampleRate: number): GateResult => {
  const normalizedPcm = normalizePcmLength(pcm)
  const actualSampleRate = sampleRate > 0 ? sampleRate : GATE_TARGET_SAMPLE_RATE

  let sumSquares = 0
  let absMax = 0
  let clippedCount = 0

  for (let i = 0; i < normalizedPcm.length; i += 1) {
    const sample = normalizedPcm[i]
    const absSample = Math.abs(sample)
    sumSquares += sample * sample
    if (absSample > absMax) {
      absMax = absSample
    }
    if (absSample > CLIP_LEVEL) {
      clippedCount += 1
    }
  }

  const rms = Math.sqrt(sumSquares / normalizedPcm.length)
  const clipRatio = clippedCount / normalizedPcm.length

  const frameCount = Math.floor(normalizedPcm.length / FRAME_SIZE)
  let speechFrameCount = 0
  let firstSpeechFrame = -1
  let lastSpeechFrame = -1

  for (let frame = 0; frame < frameCount; frame += 1) {
    const start = frame * FRAME_SIZE
    const end = start + FRAME_SIZE
    let frameSquares = 0
    for (let i = start; i < end; i += 1) {
      const sample = normalizedPcm[i]
      frameSquares += sample * sample
    }
    const frameRms = Math.sqrt(frameSquares / FRAME_SIZE)
    if (frameRms >= SPEECH_FRAME_RMS_THRESHOLD) {
      speechFrameCount += 1
      if (firstSpeechFrame === -1) {
        firstSpeechFrame = frame
      }
      lastSpeechFrame = frame
    }
  }

  const speechRatio = frameCount > 0 ? speechFrameCount / frameCount : 0
  const frameMs = (FRAME_SIZE / actualSampleRate) * 1000
  const firstSpeechMs = firstSpeechFrame === -1 ? null : Math.round(firstSpeechFrame * frameMs)
  const lastSpeechMs = lastSpeechFrame === -1 ? null : Math.round((lastSpeechFrame + 1) * frameMs)
  const speechSpanMs =
    firstSpeechMs === null || lastSpeechMs === null ? 0 : Math.max(0, lastSpeechMs - firstSpeechMs)

  const debugMetrics: GateResult['debugMetrics'] = {
    rms,
    absMax,
    clipRatio,
    speechRatio,
    firstSpeechMs,
    lastSpeechMs,
  }

  if (absMax < FLATLINE_ABS_MAX_THRESHOLD && rms < FLATLINE_RMS_THRESHOLD) {
    return buildResult('REJECT', 'Flatline', 'ë§ˆì´í¬ ì‹ í˜¸ê°€ ê±°ì˜ ì—†ì–´ìš”. ë‹¤ì‹œ ë§í•´ë³¼ê¹Œ?', debugMetrics)
  }

  if (rms < TOO_QUIET_RMS_THRESHOLD) {
    return buildResult('REJECT', 'TooQuiet', 'ì†Œë¦¬ê°€ ë„ˆë¬´ ì‘ê²Œ ë“¤ì–´ì™”ì–´ìš”. ì¡°ê¸ˆ ë” í¬ê²Œ!', debugMetrics)
  }

  if (speechRatio < NO_SPEECH_RATIO_THRESHOLD) {
    return buildResult('REJECT', 'NoSpeech', 'ë°œí™”ê°€ ê±°ì˜ ê°ì§€ë˜ì§€ ì•Šì•˜ì–´ìš”. ë‹¤ì‹œ ë˜ë ·í•˜ê²Œ!', debugMetrics)
  }

  if (rms < BORDERLINE_QUIET_RMS_THRESHOLD) {
    return buildResult('AMBIG', 'BorderlineQuiet', 'ê±°ì˜ ì¢‹ì•„ìš”! í•œ ë²ˆë§Œ ë” ë˜ë ·í•˜ê²Œ í•´ë³¼ê¹Œìš”?', debugMetrics)
  }

  if (clipRatio > CLIP_RATIO_THRESHOLD) {
    return buildResult('AMBIG', 'ClippingSuspected', 'ì†Œë¦¬ê°€ ì‚´ì§ ê¹¨ì¡Œì„ ìˆ˜ ìˆì–´ìš”. ë‹¤ì‹œ í•œ ë²ˆ!', debugMetrics)
  }

  if (
    (firstSpeechMs !== null && firstSpeechMs > LATE_START_MS) ||
    (lastSpeechMs !== null && lastSpeechMs < EARLY_END_MS) ||
    speechSpanMs < MIN_SPEECH_SPAN_MS
  ) {
    return buildResult('AMBIG', 'SpeechOffCenter', 'íƒ€ì´ë°ì´ ì¡°ê¸ˆ ì¹˜ìš°ì³¤ì–´ìš”. ì¤‘ì•™ì— ë§ì¶° ë‹¤ì‹œ!', debugMetrics)
  }

  if (speechRatio >= PASS_SPEECH_RATIO_THRESHOLD && rms >= BORDERLINE_QUIET_RMS_THRESHOLD) {
    return buildResult('PASS', 'Ok', 'ì¢‹ì•„! ì™„ë²½í•´ ğŸ‰', debugMetrics)
  }

  return buildResult('AMBIG', 'SpeechOffCenter', 'ì¡°ê¸ˆë§Œ ë” ì„ ëª…í•˜ê²Œ ë§í•˜ë©´ ë°”ë¡œ í†µê³¼ì˜ˆìš”!', debugMetrics)
}
